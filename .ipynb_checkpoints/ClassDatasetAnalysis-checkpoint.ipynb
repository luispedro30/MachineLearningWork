{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "374d8173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, pickle\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import statistics\n",
    "import math\n",
    "\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07d06bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreparation:\n",
    "    def __init__(self, outcome, features=None, categorical_features=None, one_hot_encoder=None):\n",
    "        self._outcome = outcome\n",
    "        self._features = features\n",
    "        self._categorical_features = categorical_features\n",
    "        self._one_hot_encoder = one_hot_encoder\n",
    " \n",
    "    def getData(self, path, separator):\n",
    "        data = pd.read_csv(path, sep = separator)\n",
    "        if self._features:\n",
    "            data = data[self._features]\n",
    "        return data\n",
    "    \n",
    "    def replaceValues(self,colunas, data, tipo):\n",
    "        if tipo == 'Binary':\n",
    "            for coluna in colunas:\n",
    "                coluna = data[coluna]\n",
    "                for index in range (len(coluna)):\n",
    "                    if coluna[index] >= 10:\n",
    "                        coluna[index] = 1\n",
    "                    else:\n",
    "                        coluna[index] = 0\n",
    "        elif tipo == 'FiveLevels':\n",
    "            for coluna in colunas:\n",
    "                coluna = data[coluna]\n",
    "                for index in range (len(coluna)):\n",
    "                    if coluna[index] <= 9:\n",
    "                        coluna[index] = 5\n",
    "                    elif coluna[index] >= 10 and coluna[index] <= 11 :\n",
    "                        coluna[index] = 4\n",
    "                    elif coluna[index] >= 12 and coluna[index] <= 13 :\n",
    "                        coluna[index] = 3\n",
    "                    elif coluna[index] >= 14 and coluna[index] <= 15 :\n",
    "                        coluna[index] = 2\n",
    "                    else:\n",
    "                        coluna[index] = 1\n",
    "        return data\n",
    "    \n",
    "    def getDataInfo(self,data):\n",
    "        print(\"Number of Rows: {}\\nNumber of Columns: {}\".format(data.shape[0], data.shape[1]))\n",
    "        print(\"The dataset has %d rows and %d columns \" \n",
    "              % data.shape + \"and has \" + (\"some\" if data.isnull().values.any() else \"no\")  + \" missing values.\")\n",
    "        return data.describe()\n",
    "        \n",
    "    def checkAndFillMissingValuesMode(self,data):\n",
    "        features = data.columns\n",
    "        for feature in features:\n",
    "            if (data[feature].isnull().values.any() == True):\n",
    "                print(\"-The column '{}', has'{}' missing values.\\n\"\n",
    "                .format(feature, data[feature].isnull().sum()))\n",
    "                data[feature].fillna(statistics.mode(data[feature]), inplace = True)\n",
    "        return data\n",
    "    \n",
    "    def getFeaturesTypes(self,data):\n",
    "        return(data.dtypes)\n",
    "    \n",
    "    def changeFeatureType(self,data,previousType, newType):\n",
    "        for feature in data.columns:\n",
    "            if ((data[feature].dtypes) == previousType):\n",
    "                #for value in data[feature]:\n",
    "                #value = value.astype(np.int64)\n",
    "                data[feature] = data[feature].astype(np.int64)\n",
    "        print(data.dtypes)\n",
    "        return data\n",
    "\n",
    "    def getBarPlots(self,data):\n",
    "        plt.figure(figsize = (30, 30))\n",
    "        for i in enumerate(data.columns):\n",
    "            plt.subplot(int(data.columns.size/4)+1,4,i[0]+1)\n",
    "            sns.countplot(i[1], data = data)\n",
    "        \n",
    "        \n",
    "    def getCathegoricalFeatures(self,data):\n",
    "        features = data.columns\n",
    "        numeric_features = data._get_numeric_data().columns\n",
    "        for column in data[numeric_features][:-2]:\n",
    "            print(\"-The column '{}', has values that goes from '{}' to '{}' and is '{}' type.\\n\"\n",
    "            .format(column, data[column].min(), data[column].max(), data[column].dtype))\n",
    "            \n",
    "        list_cathegorical_features = list(set(features) - set(numeric_features))\n",
    "        for column in data[list_cathegorical_features][:-2]:\n",
    "            print(\"-The column '{}' is a categorical column with values from '{}' to '{}' and is {} type\"\n",
    "          .format(column, data[column].min(), data[column].max(), data[column].dtype))\n",
    "            \n",
    "        return list_cathegorical_features\n",
    "    \n",
    "    def getFeaturesDescription(self,data, label):\n",
    "        for col in data.columns:\n",
    "            if col != label:\n",
    "                data[col].describe()\n",
    "    \n",
    "    def CorrelationMatrix(self,data):\n",
    "        plt.figure(figsize=(18,16))\n",
    "        sns.heatmap(data.corr(),annot=True)\n",
    "        plt.show()\n",
    "        \n",
    "    def Vif(self,data,label):\n",
    "        thresh = 10\n",
    "        independent_variables = []\n",
    "        print(independent_variables)\n",
    "        for col in data.columns:\n",
    "            if col != label:\n",
    "                independent_variables.append(col)\n",
    "        for i in np.arange(0, len(data)):\n",
    "            vif = [variance_inflation_factor(data[independent_variables].values,ix)\n",
    "                for ix in range(data[independent_variables].shape[1])]\n",
    "            maxloc = vif.index(max(vif))\n",
    "            if max(vif) > thresh:\n",
    "                print('vif :', vif)\n",
    "                print('dropping', data[independent_variables].columns[maxloc],\n",
    "                      'at index', maxloc)\n",
    "                del independent_variables[maxloc]\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        print('Final variables :',independent_variables)\n",
    "        return independent_variables\n",
    "    \n",
    "    def oneHotEncoding(self, data):\n",
    "        if self._categorical_features:\n",
    "            categorial = data[self._categorical_features]\n",
    "        else:\n",
    "            categorical = data.select_dtypes(exclude=np.number)\n",
    "            categorical_features = categorical.columns\n",
    "        if self._one_hot_encoder:\n",
    "            one_hot_encoder = self._one_hot_encoder\n",
    "        else:\n",
    "            one_hot_encoder = preprocessing.OneHotEncoder(\n",
    "                sparse=False,\n",
    "                drop='first')\n",
    "        categorical = one_hot_encoder.fit_transform(categorical)\n",
    "        categorical_columns = one_hot_encoder.get_feature_names_out(categorical_features)\n",
    "        categorical = pd.DataFrame(categorical, columns=categorical_columns)\n",
    "        continuous = data.select_dtypes(include=np.number)\n",
    "        data = pd.concat([categorical, continuous], axis=1)\n",
    "        return data, one_hot_encoder\n",
    "    \n",
    "    def normalizeData(self,data,label):\n",
    "        numeric_features = data.loc[:, data.columns != label].select_dtypes(include=np.number).columns.tolist()\n",
    "        \n",
    "        sc = preprocessing.StandardScaler()\n",
    "        sc.fit(data[numeric_features])\n",
    "        data[numeric_features] = sc.transform(data[numeric_features])\n",
    "        return data\n",
    "    \n",
    "    def splitData(self, data, independent_variables, size_test):\n",
    "        x, y = data[independent_variables], data.iloc[:, [-1]]\n",
    "        X_train , X_test , y_train , y_test = train_test_split(x, y, test_size = size_test, random_state = 2017)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def fit(self, X_train, y_train, algorithm):\n",
    "        model = algorithm.fit(X_train, y_train)\n",
    "        return model\n",
    "    \n",
    "    def predict(self, model, X_test):\n",
    "        result = model.predict(X_test)\n",
    "        return result\n",
    "    \n",
    "    def modelMetrics(self,model, X_test, y_test, y_test_pred):\n",
    "        print('Train MAE : ',metrics.mean_absolute_error(y_test,y_test_pred))\n",
    "        print('Train RMSE',np.sqrt(metrics.mean_squared_error(y_test,y_test_pred)))\n",
    "        print('R- Squared = ',metrics.r2_score (y_test, y_test_pred))\n",
    "        print(\"The MAE of the Model is:\", metrics.mean_absolute_error(y_test, y_test_pred))\n",
    "        print(\"Accuracy: \", metrics.accuracy_score(y_test, y_test_pred))\n",
    "        print ('Test confusion matrix \\n', metrics.confusion_matrix (y_test, y_test_pred))\n",
    "        print ('Classification report : \\n',metrics.classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "09db7b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedMlModels:\n",
    "    def __init__(self, x_train=None, x_test=None, y_train=None, y_test=None):\n",
    "        self._x_train = x_train\n",
    "        self._x_test = x_test\n",
    "        self._y_train = y_train\n",
    "        self._y_test = y_test\n",
    "        \n",
    "    def hyperparameterTuning(self, model):\n",
    "        if model == 'LogisticRegression':\n",
    "            grid = lm.LogisticRegression()\n",
    "        elif model == 'Svm':\n",
    "            param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']} \n",
    "  \n",
    "            grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    "        elif model == 'RandomForest':\n",
    "            param_grid = {\n",
    "                'bootstrap': [True],\n",
    "                'max_depth': [80, 90, 100, 110],\n",
    "                'max_features': [2, 3],\n",
    "                'min_samples_leaf': [3, 4, 5],\n",
    "                'min_samples_split': [8, 10, 12],\n",
    "                'n_estimators': [100, 200, 300, 1000]\n",
    "            }\n",
    "            grid = GridSearchCV(estimator = RandomForestRegressor(), param_grid = param_grid, \n",
    "                                      cv = 3, n_jobs = -1, verbose = 2)\n",
    "        elif model == 'DecisionTree':\n",
    "            params = {\n",
    "                'max_depth': [2, 3, 5, 10, 20],\n",
    "                'min_samples_leaf': [5, 10, 20, 50, 100],\n",
    "                'criterion': [\"gini\", \"entropy\"]\n",
    "            }\n",
    "            grid = GridSearchCV(estimator=DecisionTreeClassifier(random_state=42), \n",
    "                                       param_grid=params, \n",
    "                                       cv=10, n_jobs=-1, verbose=1, scoring = \"accuracy\")\n",
    "        elif model == 'NearestNeighbour':\n",
    "            k_range = list(range(1, 31))\n",
    "            param_grid = dict(n_neighbors=k_range)\n",
    "\n",
    "            grid = GridSearchCV(KNeighborsClassifier(), param_grid, \n",
    "                                cv=10, scoring='accuracy', return_train_score=False,verbose=1)\n",
    "        elif model == 'NaiveBayes':\n",
    "            grid = MultinomialNB();\n",
    "        else:\n",
    "            grid = 0\n",
    "        return grid\n",
    "            \n",
    "        \n",
    " \n",
    "    def fit(self, x_train, y_train, algorithm):\n",
    "        model = algorithm.fit(x_train, y_train)\n",
    "        return model\n",
    "    \n",
    "    def predict(self, model, x_test):\n",
    "        result = np.round(model.predict(x_test))\n",
    "        return result\n",
    "    \n",
    "    def modelMetrics(self,model, X_test, y_test, y_test_pred):\n",
    "        print('Train MAE : ',metrics.mean_absolute_error(y_test,y_test_pred))\n",
    "        print('Train RMSE',np.sqrt(metrics.mean_squared_error(y_test,y_test_pred)))\n",
    "        print('R- Squared = ',metrics.r2_score (y_test, y_test_pred))\n",
    "        print(\"The MAE of the Model is:\", metrics.mean_absolute_error(y_test, y_test_pred))\n",
    "        print(\"Accuracy: \", metrics.accuracy_score(y_test, y_test_pred))\n",
    "        print('Test confusion matrix \\n', metrics.confusion_matrix (y_test, y_test_pred))\n",
    "        print('Classification report : \\n',metrics.classification_report(y_test,y_test_pred))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90bb26cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
      "0       GP   F   18       U     GT3       A     4     4   at_home   teacher   \n",
      "1       GP   F   17       U     GT3       T     1     1   at_home     other   \n",
      "2       GP   F   15       U     LE3       T     1     1   at_home     other   \n",
      "3       GP   F   15       U     GT3       T     4     2    health  services   \n",
      "4       GP   F   16       U     GT3       T     3     3     other     other   \n",
      "..     ...  ..  ...     ...     ...     ...   ...   ...       ...       ...   \n",
      "390     MS   M   20       U     LE3       A     2     2  services  services   \n",
      "391     MS   M   17       U     LE3       T     3     1  services  services   \n",
      "392     MS   M   21       R     GT3       T     1     1     other     other   \n",
      "393     MS   M   18       R     LE3       T     3     2  services     other   \n",
      "394     MS   M   19       U     LE3       T     1     1     other   at_home   \n",
      "\n",
      "     ... famrel freetime  goout  Dalc  Walc health absences    G1  G2    G3  \n",
      "0    ...      4        3    4.0     1     1      3        6   5.0   6   6.0  \n",
      "1    ...      5        3    3.0     1     1      3        4   5.0   5   6.0  \n",
      "2    ...      4        3    2.0     2     3      3       10   7.0   8  10.0  \n",
      "3    ...      3        2    2.0     1     1      5        2  15.0  14  15.0  \n",
      "4    ...      4        3    2.0     1     2      5        4   6.0  10  10.0  \n",
      "..   ...    ...      ...    ...   ...   ...    ...      ...   ...  ..   ...  \n",
      "390  ...      5        5    4.0     4     5      4       11   9.0   9   9.0  \n",
      "391  ...      2        4    5.0     3     4      2        3  14.0  16  16.0  \n",
      "392  ...      5        5    3.0     3     3      3        3  10.0   8   7.0  \n",
      "393  ...      4        4    1.0     3     4      5        0  11.0  12  10.0  \n",
      "394  ...      3        2    3.0     3     3      5        5   8.0   9   9.0  \n",
      "\n",
      "[395 rows x 33 columns]\n",
      "Number of Rows: 395\n",
      "Number of Columns: 33\n",
      "The dataset has 395 rows and 33 columns and has some missing values.\n",
      "Number of Rows: 649\n",
      "Number of Columns: 33\n",
      "The dataset has 649 rows and 33 columns and has some missing values.\n",
      "-The column 'Mjob', has'1' missing values.\n",
      "\n",
      "-The column 'guardian', has'1' missing values.\n",
      "\n",
      "-The column 'paid', has'1' missing values.\n",
      "\n",
      "-The column 'goout', has'1' missing values.\n",
      "\n",
      "-The column 'G1', has'1' missing values.\n",
      "\n",
      "-The column 'G3', has'1' missing values.\n",
      "\n",
      "-The column 'address', has'1' missing values.\n",
      "\n",
      "school        object\n",
      "sex           object\n",
      "age            int64\n",
      "address       object\n",
      "famsize       object\n",
      "Pstatus       object\n",
      "Medu           int64\n",
      "Fedu           int64\n",
      "Mjob          object\n",
      "Fjob          object\n",
      "reason        object\n",
      "guardian      object\n",
      "traveltime     int64\n",
      "studytime      int64\n",
      "failures       int64\n",
      "schoolsup     object\n",
      "famsup        object\n",
      "paid          object\n",
      "activities    object\n",
      "nursery       object\n",
      "higher        object\n",
      "internet      object\n",
      "romantic      object\n",
      "famrel         int64\n",
      "freetime       int64\n",
      "goout          int64\n",
      "Dalc           int64\n",
      "Walc           int64\n",
      "health         int64\n",
      "absences       int64\n",
      "G1             int64\n",
      "G2             int64\n",
      "G3             int64\n",
      "dtype: object\n",
      "school        object\n",
      "sex           object\n",
      "age            int64\n",
      "address       object\n",
      "famsize       object\n",
      "Pstatus       object\n",
      "Medu           int64\n",
      "Fedu           int64\n",
      "Mjob          object\n",
      "Fjob          object\n",
      "reason        object\n",
      "guardian      object\n",
      "traveltime     int64\n",
      "studytime      int64\n",
      "failures       int64\n",
      "schoolsup     object\n",
      "famsup        object\n",
      "paid          object\n",
      "activities    object\n",
      "nursery       object\n",
      "higher        object\n",
      "internet      object\n",
      "romantic      object\n",
      "famrel         int64\n",
      "freetime       int64\n",
      "goout          int64\n",
      "Dalc           int64\n",
      "Walc           int64\n",
      "health         int64\n",
      "absences       int64\n",
      "G1             int64\n",
      "G2             int64\n",
      "G3             int64\n",
      "dtype: object\n",
      "[]\n",
      "vif : [1.6185431830766923, 2.7949639648741473, 6.014528538973632, 1.6302256163118203, 10.826279288872037, 2.5243212834112456, 4.287982584512701, 3.8807638514625213, 3.7230818044988596, 2.077105405008677, 12.098809993060303, 6.569431797978863, 2.706085079313097, 1.9901292903707954, 1.415710869072321, 2.076417330168094, 4.782276506498285, 1.7990080225383134, 1.3193549897495402, 3.2912625059527816, 2.3682881514673007, 2.3627645708377347, 5.604479719724703, 21.039764927135558, 7.449465437040348, 1.7516565885792073, 90.95231515289763, 21.531718025372676, 13.600858519812087, 6.591376229959463, 9.574524676542088, 1.8723964685740573, 23.15613301697648, 14.649810115485007, 13.10925220129985, 7.650865043217793, 10.04230817855407, 8.602378753761288, 1.905893626358726, 6.795326843435945, 6.604294476705578]\n",
      "dropping age at index 26\n",
      "vif : [1.4745005505319653, 2.7939788544654434, 5.793841697406115, 1.6213285339289085, 9.882653575913888, 2.5200658791693757, 4.279742874414566, 3.880476280409761, 3.7163551305009266, 2.0441470963425563, 11.432653427995259, 6.246615604120434, 2.605841249853485, 1.9829885091659638, 1.4079124320021632, 2.0636692951010533, 4.548399345336093, 1.6838938262957868, 1.3133230216614376, 3.2912624756340225, 2.3643547118078594, 2.3597189655789874, 5.453823093255203, 20.0749259394915, 7.444584270947458, 1.736952287006401, 21.518680202443704, 13.435107051437253, 6.395522158549537, 8.954287399061876, 1.7822402329972162, 21.068206987315424, 14.407204908781802, 12.99365154245651, 7.641111968665425, 9.967497205699544, 8.41536002289762, 1.853982716541283, 6.794465340685898, 6.564558971803507]\n",
      "dropping Medu at index 26\n",
      "vif : [1.4742642132378287, 2.7885469261328186, 5.748459919776925, 1.598805219513474, 9.814071684875044, 1.9875175360127058, 4.009831677076068, 3.334699756192727, 2.728175280148596, 2.0374675360430397, 11.362370895221996, 6.246397527193329, 2.60091117451397, 1.9827788715945294, 1.4060471288776952, 2.05913597141587, 4.488948679175637, 1.6807645158676874, 1.313060207501896, 3.285544896341102, 2.36408911971946, 2.359517100926214, 5.434281202435764, 20.07302801623209, 7.440124900440046, 1.723776328428747, 9.709962913988068, 6.392241800357327, 8.808050665650141, 1.7822124605591914, 21.022070333694653, 14.404401754025209, 12.943168162918223, 7.514319858572634, 9.849893115195707, 8.304379905285026, 1.8191179675261082, 6.794382152642059, 6.549722831238057]\n",
      "dropping famrel at index 30\n",
      "vif : [1.4739288296956834, 2.7659043471907663, 5.7321865925241, 1.5974851452665035, 9.70489944490972, 1.9719192109831787, 4.0092973207478, 3.3345564202920404, 2.716112689412138, 2.0127760717133616, 11.010024601831448, 5.9640642218192985, 2.585648528832422, 1.9811929393286625, 1.4020498864792905, 2.0564808687723986, 4.44354437739186, 1.665704658669561, 1.312780137563819, 3.2806383304559765, 2.3632007768933243, 2.3564879902364293, 5.421868493997118, 19.66345183260723, 7.411619731100378, 1.7216534507603487, 9.599821508759492, 6.32430196984403, 8.707996061893795, 1.7822123645265266, 13.722812782137126, 12.752784746168604, 7.504280938152419, 9.701600466660622, 8.010698651890396, 1.8182907391242085, 6.790800809824583, 6.546742803375471]\n",
      "dropping higher_yes at index 23\n",
      "vif : [1.459882288408338, 2.729130154691737, 5.674732654075075, 1.5943650139479324, 9.597771946040874, 1.9526808525371744, 3.943067052760778, 3.2911054599125174, 2.7029620148228193, 1.999250141425754, 10.734004921339453, 5.885797053272083, 2.5625358925441666, 1.9515335392983526, 1.3992012123383641, 2.0453507690476354, 4.390101974110769, 1.6465923022814413, 1.3040224221726364, 3.279700031899507, 2.352186546247149, 2.349469082076551, 5.388163978875417, 7.410452641192197, 1.7041526021034672, 9.292167989987908, 6.256265184887598, 8.429188526026055, 1.7565027699123281, 13.58178993283589, 12.750362882278171, 7.494337401916416, 9.696059932285973, 7.883129704295878, 1.81635769436151, 6.770444786205658, 6.5413380047810605]\n",
      "dropping freetime at index 29\n",
      "vif : [1.447810351770694, 2.668985602334773, 5.603575414287011, 1.5941244917817592, 9.437314149992961, 1.9507087823155616, 3.912242368425616, 3.277849093720579, 2.679575983679595, 1.99756241671044, 10.70302592962154, 5.885758060024168, 2.562478861189137, 1.9409125897261998, 1.3967872221167712, 2.045338906759428, 4.36784506457928, 1.6243085611505104, 1.3020120991683892, 3.252351023399235, 2.344512137011827, 2.32594808642425, 5.360721334575883, 7.38932544330654, 1.7041208716344125, 9.288418045710868, 6.255909628800569, 8.42911392320035, 1.743470875920482, 11.774534107308986, 7.360936081992217, 9.6671840914626, 7.745265802856902, 1.811117412821891, 6.711471059367552, 6.540818868581614]\n",
      "dropping goout at index 29\n",
      "vif : [1.4442589233674281, 2.667575219729764, 5.401929574280472, 1.5941191216175625, 9.378612888242392, 1.9400713169938522, 3.885475625856725, 3.268814002902852, 2.677217975349967, 1.9974009654756055, 10.690630978927647, 5.885545497699898, 2.559329632698567, 1.9400134771942326, 1.3943104925430923, 2.043919369086915, 4.236952142648016, 1.617246291832879, 1.3015697185550652, 3.251662965683982, 2.337680211172125, 2.30594952849329, 5.331695908592925, 7.336801251870359, 1.7026087811104138, 9.118185607932666, 6.232911266596249, 8.299463209146209, 1.7281564748142053, 7.355774508696925, 8.481837922980796, 7.741198557893899, 1.808812886140213, 6.6683109673746435, 6.380721048894328]\n",
      "dropping Fjob_other at index 10\n",
      "Final variables : ['school_MS', 'sex_M', 'address_U', 'famsize_LE3', 'Pstatus_T', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_health', 'Fjob_services', 'Fjob_teacher', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_mother', 'guardian_other', 'schoolsup_yes', 'famsup_yes', 'paid_yes', 'activities_yes', 'nursery_yes', 'internet_yes', 'romantic_yes', 'Fedu', 'traveltime', 'studytime', 'failures', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "vif : [2.3786680425209634, 2.357506638526686, 4.273356896523521, 1.6241224090582826, 9.505362599603048, 1.9445625977585426, 3.3378692582989378, 2.6848952851809735, 2.5589165307233293, 1.802346044057598, 10.380134317771931, 5.640696020296282, 2.2546136047514764, 1.712363461516526, 1.3888277410677021, 1.7894704472690308, 4.549420465643674, 1.606989079657556, 1.2465428092894157, 2.865664516069903, 1.1704466866865884, 2.2190553622268068, 5.377253572546223, 12.42039195056121, 5.352458679705672, 1.7669508617759153, 83.67053634093212, 15.871546539640278, 11.30179352701782, 6.7396295661003895, 7.993154011352206, 1.7124307112986974, 19.844141649772272, 12.4557956549778, 12.186653203709447, 6.691780758744027, 8.769370816446521, 7.913749317517345, 1.9915688423321738, 8.348465308172631, 8.22865940535195]\n",
      "dropping age at index 26\n",
      "vif : [2.1771158688513155, 2.350832748421533, 4.019458217805444, 1.6057594657014402, 8.655688344553306, 1.9426768655197433, 3.3098551213948486, 2.683566006746238, 2.5471572841799475, 1.7929288845314373, 9.889442859072693, 5.3844928483210674, 2.191402673480574, 1.7016377011435053, 1.3847763328206901, 1.7735300327680759, 4.261682990202359, 1.4887601850083383, 1.24623322000913, 2.8644166204409673, 1.1693575556200506, 2.211701344787706, 5.242878557209244, 12.355679401446183, 5.327096424675698, 1.7385433032818598, 15.68105292998544, 11.250511717379087, 6.426362283045433, 7.5455732549744665, 1.5784402608046368, 18.274377073370406, 12.228105129651233, 12.12428965800568, 6.666970766878748, 8.714937202008015, 7.661405212006438, 1.929919988019078, 8.335119939141366, 8.047274284257826]\n",
      "dropping famrel at index 31\n",
      "vif : [2.1629938898428547, 2.3257778478659117, 4.011524771971394, 1.601556458534075, 8.506839488980434, 1.9303209939478947, 3.309734999225361, 2.679564992013666, 2.535219515470617, 1.7786070137515944, 9.628029146081941, 5.193434211146292, 2.1832429912287994, 1.6996525682971702, 1.3798255732010685, 1.766636962749092, 4.244241644840982, 1.4887556656693242, 1.2461651619052334, 2.8604097170530602, 1.1689428569954454, 2.2116588353289215, 5.212526172263284, 12.29665838440671, 5.285936127708703, 1.7381841115148067, 15.632721333168407, 11.242517821139973, 6.367686159490742, 7.534798570333964, 1.5761242557317798, 11.881670365389494, 11.88844867968598, 6.6635132155295596, 8.584290308886185, 7.3663353247224475, 1.9297642931677539, 8.334906316877982, 7.9348599054130995]\n",
      "dropping Medu at index 26\n",
      "vif : [2.1628012047283813, 2.31134202896087, 3.998079630237689, 1.6002898840397168, 8.504509256665528, 1.6602275984579362, 3.1832150316813954, 2.468413101860524, 2.0590248157388427, 1.7767197515223143, 9.599777248560212, 5.193366922706731, 2.1823895964974733, 1.699166888805302, 1.3786546306680765, 1.759450937096455, 4.184850173623449, 1.4886664167751396, 1.2453741544005164, 2.8553451011226225, 1.1605716358413014, 2.209844532325205, 5.157298201171516, 12.25882887345547, 5.256360414935641, 1.7336441286873794, 8.10774137458605, 6.346193193237249, 7.481076800553771, 1.576123817589509, 11.861119599807509, 11.864647944138257, 6.612713591491635, 8.504222625226756, 7.352361711048495, 1.929596981151915, 8.334512517558505, 7.932216809996752]\n",
      "dropping higher_yes at index 23\n",
      "vif : [2.1379445901506804, 2.311301999914429, 3.976421886344806, 1.600128341914544, 8.442549906117627, 1.6371620705156618, 3.1468480686576887, 2.46180048495769, 2.0508045446134373, 1.7756102017416633, 9.468662944502519, 5.11791412587366, 2.1760937040653485, 1.6979544178450334, 1.3784121495896207, 1.7572482217219465, 4.134579405164857, 1.4833403812288963, 1.2313939407545602, 2.8436959419957097, 1.159510558790356, 2.2094763928395924, 5.153031575822972, 5.255828082069484, 1.7323561330255364, 7.977612371844199, 6.282015510727446, 7.356899578365587, 1.5675564155931674, 11.860127379085753, 11.858602181323347, 6.607809964013509, 8.500796444774968, 7.316326261343294, 1.929596890577086, 7.927336477631341, 7.85836997718704]\n",
      "dropping freetime at index 29\n",
      "vif : [2.1159117985967075, 2.2719659603485867, 3.9708563749289265, 1.5999491301480075, 8.364435402681705, 1.6369915498861647, 3.1439529159817092, 2.461538850269395, 2.0454007909758865, 1.7751592521418844, 9.428689399000811, 5.111147852674807, 2.1751802614353077, 1.697379124152184, 1.3778785428653895, 1.756980074771598, 4.106070635504613, 1.480336722035454, 1.2284421062774138, 2.8385846662805903, 1.1493120194759632, 2.185181200427489, 5.144929101084076, 5.234693280683545, 1.7273723170151192, 7.945918366040215, 6.276283371880038, 7.3386905217638185, 1.5518055175909247, 10.28843150989814, 6.59766122957, 8.468735673011711, 7.144170863729978, 1.928247109818847, 7.91827543462096, 7.844000758151572]\n",
      "dropping goout at index 29\n",
      "Final variables : ['school_MS', 'sex_M', 'address_U', 'famsize_LE3', 'Pstatus_T', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_mother', 'guardian_other', 'schoolsup_yes', 'famsup_yes', 'paid_yes', 'activities_yes', 'nursery_yes', 'internet_yes', 'romantic_yes', 'Fedu', 'traveltime', 'studytime', 'failures', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    path1 = 'Datasets\\student-mat.csv'\n",
    "    path2 = 'Datasets\\student-por.csv'\n",
    "    model_instance = DataPreparation(outcome = 'yes', features=None, categorical_features=None, one_hot_encoder=None)\n",
    "    data_math = model_instance.getData(path1, separator = ';')\n",
    "    print(data_math)\n",
    "    data_por = model_instance.getData(path2, separator = ';')\n",
    "    data_info_mat = model_instance.getDataInfo(data_math) \n",
    "    data_info_por = model_instance.getDataInfo(data_por)\n",
    "    data_math = model_instance.checkAndFillMissingValuesMode(data_math)\n",
    "    data_por = model_instance.checkAndFillMissingValuesMode(data_por)\n",
    "    features_types_mat = model_instance.getFeaturesTypes(data_math)\n",
    "    data_math = model_instance.changeFeatureType(data_math, 'float64', 'int64')\n",
    "    dat_por = model_instance.changeFeatureType(data_por, 'float64', 'int64')\n",
    "    data_math = model_instance.replaceValues(['G1','G2','G3'], data_math, tipo = 'Binary')\n",
    "    dat_por = model_instance.replaceValues(['G1','G2','G3'], dat_por, tipo = 'Binary')\n",
    "    \n",
    "    \"\"\"\n",
    "    data_math = model_instance.normalizeData(data_math,'G3')\n",
    "    dat_por = model_instance.normalizeData(dat_por,'G3')\n",
    "    \"\"\"\n",
    "    \n",
    "    data_math, one_hot_math = model_instance.oneHotEncoding(data_math)\n",
    "    independent_variables_math = model_instance.Vif(data_math,'G3')\n",
    "    X_train_math, X_test_math, y_train_math, y_test_math = model_instance.splitData(data_math, \n",
    "                                                                     independent_variables_math, \n",
    "                                                                     size_test = 0.3)\n",
    "    \n",
    "    data_por, one_hot_por = model_instance.oneHotEncoding(data_por)\n",
    "    independent_variables_por = model_instance.Vif(data_por,'G3')\n",
    "    X_train_por, X_test_por, y_train_por, y_test_por = model_instance.splitData(data_por, \n",
    "                                                                     independent_variables_por, \n",
    "                                                                     size_test = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30d62a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O algoritmo escolhido foi LogisticRegression\n",
      "Train MAE :  0.08403361344537816\n",
      "Train RMSE 0.28988551782622424\n",
      "R- Squared =  0.6234177215189873\n",
      "The MAE of the Model is: 0.08403361344537816\n",
      "Accuracy:  0.9159663865546218\n",
      "Test confusion matrix \n",
      " [[37  3]\n",
      " [ 7 72]]\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88        40\n",
      "           1       0.96      0.91      0.94        79\n",
      "\n",
      "    accuracy                           0.92       119\n",
      "   macro avg       0.90      0.92      0.91       119\n",
      "weighted avg       0.92      0.92      0.92       119\n",
      "\n",
      "\n",
      "None\n",
      "O algoritmo escolhido foi DecisionTree\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "Train MAE :  0.08403361344537816\n",
      "Train RMSE 0.28988551782622424\n",
      "R- Squared =  0.6234177215189873\n",
      "The MAE of the Model is: 0.08403361344537816\n",
      "Accuracy:  0.9159663865546218\n",
      "Test confusion matrix \n",
      " [[38  2]\n",
      " [ 8 71]]\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88        40\n",
      "           1       0.97      0.90      0.93        79\n",
      "\n",
      "    accuracy                           0.92       119\n",
      "   macro avg       0.90      0.92      0.91       119\n",
      "weighted avg       0.92      0.92      0.92       119\n",
      "\n",
      "\n",
      "None\n",
      "O algoritmo escolhido foi Svm\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.661 total time=   0.0s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.661 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.661 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.661 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.661 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.661 total time=   0.0s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.821 total time=   0.0s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.782 total time=   0.0s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.727 total time=   0.0s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.800 total time=   0.0s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.782 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.768 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.745 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.782 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.764 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.855 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.661 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.655 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.661 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.661 total time=   0.0s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.818 total time=   0.0s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.745 total time=   0.0s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.873 total time=   0.0s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.818 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.911 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.909 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.836 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.891 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.909 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.836 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.873 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.661 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.655 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.661 total time=   0.0s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.818 total time=   0.0s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.745 total time=   0.0s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.873 total time=   0.0s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.818 total time=   0.0s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.911 total time=   0.0s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.891 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.836 total time=   0.0s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.873 total time=   0.0s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.911 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.964 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.855 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.927 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.891 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.893 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.909 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.836 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.873 total time=   0.0s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.661 total time=   0.0s\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.818 total time=   0.0s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.745 total time=   0.0s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.873 total time=   0.0s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.818 total time=   0.0s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.946 total time=   0.0s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.927 total time=   0.0s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.782 total time=   0.0s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.836 total time=   0.0s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.800 total time=   0.0s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.893 total time=   0.0s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.909 total time=   0.0s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.873 total time=   0.0s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.836 total time=   0.0s\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.911 total time=   0.0s\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.982 total time=   0.0s\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.855 total time=   0.0s\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.927 total time=   0.0s\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.891 total time=   0.0s\n",
      "Train MAE :  0.08403361344537816\n",
      "Train RMSE 0.28988551782622424\n",
      "R- Squared =  0.6234177215189873\n",
      "The MAE of the Model is: 0.08403361344537816\n",
      "Accuracy:  0.9159663865546218\n",
      "Test confusion matrix \n",
      " [[38  2]\n",
      " [ 8 71]]\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88        40\n",
      "           1       0.97      0.90      0.93        79\n",
      "\n",
      "    accuracy                           0.92       119\n",
      "   macro avg       0.90      0.92      0.91       119\n",
      "weighted avg       0.92      0.92      0.92       119\n",
      "\n",
      "\n",
      "None\n",
      "O algoritmo escolhido foi RandomForest\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "Train MAE :  0.14285714285714285\n",
      "Train RMSE 0.3779644730092272\n",
      "R- Squared =  0.3598101265822784\n",
      "The MAE of the Model is: 0.14285714285714285\n",
      "Accuracy:  0.8571428571428571\n",
      "Test confusion matrix \n",
      " [[29 11]\n",
      " [ 6 73]]\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.72      0.77        40\n",
      "           1       0.87      0.92      0.90        79\n",
      "\n",
      "    accuracy                           0.86       119\n",
      "   macro avg       0.85      0.82      0.83       119\n",
      "weighted avg       0.86      0.86      0.85       119\n",
      "\n",
      "\n",
      "None\n",
      "O algoritmo escolhido foi NearestNeighbour\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Train MAE :  0.23529411764705882\n",
      "Train RMSE 0.48507125007266594\n",
      "R- Squared =  -0.05443037974683573\n",
      "The MAE of the Model is: 0.23529411764705882\n",
      "Accuracy:  0.7647058823529411\n",
      "Test confusion matrix \n",
      " [[23 17]\n",
      " [11 68]]\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.57      0.62        40\n",
      "           1       0.80      0.86      0.83        79\n",
      "\n",
      "    accuracy                           0.76       119\n",
      "   macro avg       0.74      0.72      0.73       119\n",
      "weighted avg       0.76      0.76      0.76       119\n",
      "\n",
      "\n",
      "None\n",
      "O algoritmo escolhido foi NaiveBayes\n",
      "Train MAE :  0.20168067226890757\n",
      "Train RMSE 0.44908871313907184\n",
      "R- Squared =  0.09620253164556947\n",
      "The MAE of the Model is: 0.20168067226890757\n",
      "Accuracy:  0.7983193277310925\n",
      "Test confusion matrix \n",
      " [[22 18]\n",
      " [ 6 73]]\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.55      0.65        40\n",
      "           1       0.80      0.92      0.86        79\n",
      "\n",
      "    accuracy                           0.80       119\n",
      "   macro avg       0.79      0.74      0.75       119\n",
      "weighted avg       0.80      0.80      0.79       119\n",
      "\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    model_ml_math = SupervisedMlModels(x_train=None, x_test=None, y_train=None, y_test = None)\n",
    "    algorithms_math = ['LogisticRegression','DecisionTree','Svm','RandomForest','NearestNeighbour','NaiveBayes']\n",
    "    #algorithms_math = ['LinearRegression']\n",
    "    for algorithm in algorithms_math:\n",
    "        model_math = model_ml_math.hyperparameterTuning(algorithm)\n",
    "        if model_math != 0:\n",
    "            print('O algoritmo escolhido foi',algorithm)\n",
    "            model_ml_math.fit(X_train_math, y_train_math, model_math)\n",
    "            y_test_pred_math = model_ml_math.predict(model_math,X_test_math)\n",
    "            print(model_ml_math.modelMetrics(model_math,X_test_math,y_test_math, y_test_pred_math))\n",
    "            pickle.dump(model_math,open(\"Models/Maths/Binary/\"+algorithm+'.pkl','wb'))\n",
    "        else:\n",
    "            print(\"O seguinte modelo no existe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cbae934b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O algoritmo escolhido foi LogisticRegression\n",
      "Train MAE :  0.08205128205128205\n",
      "Train RMSE 0.28644594961577313\n",
      "R- Squared =  0.36969696969696964\n",
      "The MAE of the Model is: 0.08205128205128205\n",
      "Accuracy:  0.9179487179487179\n",
      "Test confusion matrix \n",
      " [[ 23   7]\n",
      " [  9 156]]\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.74        30\n",
      "           1       0.96      0.95      0.95       165\n",
      "\n",
      "    accuracy                           0.92       195\n",
      "   macro avg       0.84      0.86      0.85       195\n",
      "weighted avg       0.92      0.92      0.92       195\n",
      "\n",
      "\n",
      "O algoritmo escolhido foi DecisionTree\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "Train MAE :  0.08205128205128205\n",
      "Train RMSE 0.28644594961577313\n",
      "R- Squared =  0.36969696969696964\n",
      "The MAE of the Model is: 0.08205128205128205\n",
      "Accuracy:  0.9179487179487179\n",
      "Test confusion matrix \n",
      " [[ 24   6]\n",
      " [ 10 155]]\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75        30\n",
      "           1       0.96      0.94      0.95       165\n",
      "\n",
      "    accuracy                           0.92       195\n",
      "   macro avg       0.83      0.87      0.85       195\n",
      "weighted avg       0.92      0.92      0.92       195\n",
      "\n",
      "\n",
      "O algoritmo escolhido foi Svm\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.844 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.844 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.844 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.844 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.844 total time=   0.0s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.844 total time=   0.0s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.856 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.844 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.844 total time=   0.0s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.844 total time=   0.0s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.901 total time=   0.0s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.867 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.923 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.934 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.912 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.878 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.856 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.844 total time=   0.0s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.844 total time=   0.0s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.901 total time=   0.0s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.867 total time=   0.0s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.890 total time=   0.0s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.912 total time=   0.0s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.923 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.912 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.890 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.934 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.889 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.846 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.878 total time=   0.0s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.844 total time=   0.0s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.901 total time=   0.0s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.867 total time=   0.0s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.890 total time=   0.0s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.890 total time=   0.0s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.912 total time=   0.0s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.844 total time=   0.0s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.901 total time=   0.0s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.901 total time=   0.0s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.923 total time=   0.0s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.867 total time=   0.0s\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.934 total time=   0.0s\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.901 total time=   0.0s\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.923 total time=   0.0s\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.889 total time=   0.0s\n",
      "Train MAE :  0.1076923076923077\n",
      "Train RMSE 0.3281650616569468\n",
      "R- Squared =  0.17272727272727273\n",
      "The MAE of the Model is: 0.1076923076923077\n",
      "Accuracy:  0.8923076923076924\n",
      "Test confusion matrix \n",
      " [[ 22   8]\n",
      " [ 13 152]]\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.73      0.68        30\n",
      "           1       0.95      0.92      0.94       165\n",
      "\n",
      "    accuracy                           0.89       195\n",
      "   macro avg       0.79      0.83      0.81       195\n",
      "weighted avg       0.90      0.89      0.90       195\n",
      "\n",
      "\n",
      "O algoritmo escolhido foi RandomForest\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "Train MAE :  0.11282051282051282\n",
      "Train RMSE 0.3358876491038526\n",
      "R- Squared =  0.1333333333333333\n",
      "The MAE of the Model is: 0.11282051282051282\n",
      "Accuracy:  0.8871794871794871\n",
      "Test confusion matrix \n",
      " [[ 11  19]\n",
      " [  3 162]]\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.37      0.50        30\n",
      "           1       0.90      0.98      0.94       165\n",
      "\n",
      "    accuracy                           0.89       195\n",
      "   macro avg       0.84      0.67      0.72       195\n",
      "weighted avg       0.88      0.89      0.87       195\n",
      "\n",
      "\n",
      "O algoritmo escolhido foi NearestNeighbour\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Train MAE :  0.13846153846153847\n",
      "Train RMSE 0.3721042037676254\n",
      "R- Squared =  -0.06363636363636371\n",
      "The MAE of the Model is: 0.13846153846153847\n",
      "Accuracy:  0.8615384615384616\n",
      "Test confusion matrix \n",
      " [[  5  25]\n",
      " [  2 163]]\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.17      0.27        30\n",
      "           1       0.87      0.99      0.92       165\n",
      "\n",
      "    accuracy                           0.86       195\n",
      "   macro avg       0.79      0.58      0.60       195\n",
      "weighted avg       0.84      0.86      0.82       195\n",
      "\n",
      "\n",
      "O algoritmo escolhido foi NaiveBayes\n",
      "Train MAE :  0.11794871794871795\n",
      "Train RMSE 0.34343662872314296\n",
      "R- Squared =  0.09393939393939388\n",
      "The MAE of the Model is: 0.11794871794871795\n",
      "Accuracy:  0.882051282051282\n",
      "Test confusion matrix \n",
      " [[ 18  12]\n",
      " [ 11 154]]\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.60      0.61        30\n",
      "           1       0.93      0.93      0.93       165\n",
      "\n",
      "    accuracy                           0.88       195\n",
      "   macro avg       0.77      0.77      0.77       195\n",
      "weighted avg       0.88      0.88      0.88       195\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    model_ml_por = SupervisedMlModels(x_train=None, x_test=None, y_train=None, y_test = None)\n",
    "    algorithms_por = ['LogisticRegression','DecisionTree','Svm','RandomForest','NearestNeighbour','NaiveBayes']\n",
    "    for algorithm in algorithms_por:\n",
    "        model_por = model_ml_por.hyperparameterTuning(algorithm)\n",
    "        if model_por != 0:\n",
    "            print('O algoritmo escolhido foi',algorithm)\n",
    "            model_ml_por.fit(X_train_por, y_train_por, model_por)\n",
    "            y_test_pred_por = model_ml_por.predict(model_por,X_test_por)\n",
    "            model_ml_por.modelMetrics(model_por,X_test_por,y_test_por, y_test_pred_por)\n",
    "            pickle.dump(model_por,open(\"Models/Portuguese/Binary/\"+algorithm+'.pkl','wb'))\n",
    "        else:\n",
    "            print(\"O seguinte modelo no existe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba87831f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
