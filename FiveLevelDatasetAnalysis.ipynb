{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "374d8173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, pickle\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import statistics\n",
    "import math\n",
    "\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "07d06bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreparation:\n",
    "    def __init__(self, outcome, features=None, categorical_features=None, one_hot_encoder=None):\n",
    "        self._outcome = outcome\n",
    "        self._features = features\n",
    "        self._categorical_features = categorical_features\n",
    "        self._one_hot_encoder = one_hot_encoder\n",
    " \n",
    "    def getData(self, path, separator):\n",
    "        data = pd.read_csv(path, sep = separator)\n",
    "        if self._features:\n",
    "            data = data[self._features]\n",
    "        return data\n",
    "    \n",
    "    def replaceValues(self,colunas, data, tipo):\n",
    "        if tipo == 'Binary':\n",
    "            for coluna in colunas:\n",
    "                coluna = data[coluna]\n",
    "                for index in range (len(coluna)):\n",
    "                    if coluna[index] >= 10:\n",
    "                        coluna[index] = 1\n",
    "                    else:\n",
    "                        coluna[index] = 0\n",
    "        elif tipo == 'FiveLevels':\n",
    "            for coluna in colunas:\n",
    "                coluna = data[coluna]\n",
    "                for index in range (len(coluna)):\n",
    "                    if coluna[index] <= 9:\n",
    "                        coluna[index] = 5\n",
    "                    elif coluna[index] >= 10 and coluna[index] <= 11 :\n",
    "                        coluna[index] = 4\n",
    "                    elif coluna[index] >= 12 and coluna[index] <= 13 :\n",
    "                        coluna[index] = 3\n",
    "                    elif coluna[index] >= 14 and coluna[index] <= 15 :\n",
    "                        coluna[index] = 2\n",
    "                    else:\n",
    "                        coluna[index] = 1\n",
    "        return data\n",
    "    \n",
    "    def getDataInfo(self,data):\n",
    "        print(\"Number of Rows: {}\\nNumber of Columns: {}\".format(data.shape[0], data.shape[1]))\n",
    "        print(\"The dataset has %d rows and %d columns \" \n",
    "              % data.shape + \"and has \" + (\"some\" if data.isnull().values.any() else \"no\")  + \" missing values.\")\n",
    "        return data.describe()\n",
    "        \n",
    "    def checkAndFillMissingValuesMode(self,data):\n",
    "        features = data.columns\n",
    "        for feature in features:\n",
    "            if (data[feature].isnull().values.any() == True):\n",
    "                print(\"-The column '{}', has'{}' missing values.\\n\"\n",
    "                .format(feature, data[feature].isnull().sum()))\n",
    "                data[feature].fillna(statistics.mode(data[feature]), inplace = True)\n",
    "        return data\n",
    "    \n",
    "    def getFeaturesTypes(self,data):\n",
    "        return(data.dtypes)\n",
    "    \n",
    "    def changeFeatureType(self,data,previousType, newType):\n",
    "        for feature in data.columns:\n",
    "            if ((data[feature].dtypes) == previousType):\n",
    "                #for value in data[feature]:\n",
    "                #value = value.astype(np.int64)\n",
    "                data[feature] = data[feature].astype(np.int64)\n",
    "        print(data.dtypes)\n",
    "        return data\n",
    "\n",
    "    def getBarPlots(self,data):\n",
    "        plt.figure(figsize = (30, 30))\n",
    "        for i in enumerate(data.columns):\n",
    "            plt.subplot(int(data.columns.size/4)+1,4,i[0]+1)\n",
    "            sns.countplot(i[1], data = data)\n",
    "        \n",
    "        \n",
    "    def getCathegoricalFeatures(self,data):\n",
    "        features = data.columns\n",
    "        numeric_features = data._get_numeric_data().columns\n",
    "        for column in data[numeric_features][:-2]:\n",
    "            print(\"-The column '{}', has values that goes from '{}' to '{}' and is '{}' type.\\n\"\n",
    "            .format(column, data[column].min(), data[column].max(), data[column].dtype))\n",
    "            \n",
    "        list_cathegorical_features = list(set(features) - set(numeric_features))\n",
    "        for column in data[list_cathegorical_features][:-2]:\n",
    "            print(\"-The column '{}' is a categorical column with values from '{}' to '{}' and is {} type\"\n",
    "          .format(column, data[column].min(), data[column].max(), data[column].dtype))\n",
    "            \n",
    "        return list_cathegorical_features\n",
    "    \n",
    "    def getFeaturesDescription(self,data, label):\n",
    "        for col in data.columns:\n",
    "            if col != label:\n",
    "                data[col].describe()\n",
    "    \n",
    "    def CorrelationMatrix(self,data):\n",
    "        plt.figure(figsize=(18,16))\n",
    "        sns.heatmap(data.corr(),annot=True)\n",
    "        plt.show()\n",
    "        \n",
    "    def Vif(self,data,label):\n",
    "        thresh = 10\n",
    "        independent_variables = []\n",
    "        print(independent_variables)\n",
    "        for col in data.columns:\n",
    "            if col != label:\n",
    "                independent_variables.append(col)\n",
    "        for i in np.arange(0, len(data)):\n",
    "            vif = [variance_inflation_factor(data[independent_variables].values,ix)\n",
    "                for ix in range(data[independent_variables].shape[1])]\n",
    "            maxloc = vif.index(max(vif))\n",
    "            if max(vif) > thresh:\n",
    "                print('vif :', vif)\n",
    "                print('dropping', data[independent_variables].columns[maxloc],\n",
    "                      'at index', maxloc)\n",
    "                del independent_variables[maxloc]\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        print('Final variables :',independent_variables)\n",
    "        return independent_variables\n",
    "    \n",
    "    def oneHotEncoding(self, data):\n",
    "        if self._categorical_features:\n",
    "            categorial = data[self._categorical_features]\n",
    "        else:\n",
    "            categorical = data.select_dtypes(exclude=np.number)\n",
    "            categorical_features = categorical.columns\n",
    "        if self._one_hot_encoder:\n",
    "            one_hot_encoder = self._one_hot_encoder\n",
    "        else:\n",
    "            one_hot_encoder = preprocessing.OneHotEncoder(\n",
    "                sparse=False,\n",
    "                drop='first')\n",
    "        categorical = one_hot_encoder.fit_transform(categorical)\n",
    "        categorical_columns = one_hot_encoder.get_feature_names_out(categorical_features)\n",
    "        categorical = pd.DataFrame(categorical, columns=categorical_columns)\n",
    "        continuous = data.select_dtypes(include=np.number)\n",
    "        data = pd.concat([categorical, continuous], axis=1)\n",
    "        return data, one_hot_encoder\n",
    "    \n",
    "    def normalizeData(self,data,label):\n",
    "        #numeric_features = data.loc[:, data.columns != label].select_dtypes(include=np.number).columns.tolist()\n",
    "        numeric_features = ['age','Medu','Fedu','traveltime','studytime','failures','absences','famrel','freetime',\n",
    "                            'goout','Dalc','Walc','health']\n",
    "        \n",
    "        sc = preprocessing.StandardScaler()\n",
    "        sc.fit(data[numeric_features])\n",
    "        data[numeric_features] = sc.transform(data[numeric_features])\n",
    "        return data\n",
    "    \n",
    "    def splitData(self, data, independent_variables, size_test):\n",
    "        x, y = data[independent_variables], data.iloc[:, [-1]]\n",
    "        X_train , X_test , y_train , y_test = train_test_split(x, y, test_size = size_test, random_state = 2017)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def fit(self, X_train, y_train, algorithm):\n",
    "        model = algorithm.fit(X_train, y_train)\n",
    "        return model\n",
    "    \n",
    "    def predict(self, model, X_test):\n",
    "        result = model.predict(X_test)\n",
    "        return result\n",
    "    \n",
    "    def modelMetrics(self,model, X_test, y_test, y_test_pred):\n",
    "        print('Train MAE : ',metrics.mean_absolute_error(y_test,y_test_pred))\n",
    "        print('Train RMSE',np.sqrt(metrics.mean_squared_error(y_test,y_test_pred)))\n",
    "        print('R- Squared = ',metrics.r2_score (y_test, y_test_pred))\n",
    "        print(\"The MAE of the Model is:\", metrics.mean_absolute_error(y_test, y_test_pred))\n",
    "        print(\"Accuracy: \", metrics.accuracy_score(y_test, y_test_pred))\n",
    "        print ('Test confusion matrix \\n', metrics.confusion_matrix (y_test, y_test_pred))\n",
    "        print ('Classification report : \\n',metrics.classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "09db7b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedMlModels:\n",
    "    def __init__(self, x_train=None, x_test=None, y_train=None, y_test=None):\n",
    "        self._x_train = x_train\n",
    "        self._x_test = x_test\n",
    "        self._y_train = y_train\n",
    "        self._y_test = y_test\n",
    "        \n",
    "    def hyperparameterTuning(self, model):\n",
    "        if model == 'LogisticRegression':\n",
    "            grid = lm.LogisticRegression()\n",
    "        elif model == 'Svm':\n",
    "            param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']} \n",
    "  \n",
    "            grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    "        elif model == 'RandomForest':\n",
    "            param_grid = {\n",
    "                'bootstrap': [True],\n",
    "                'max_depth': [80, 90, 100, 110],\n",
    "                'max_features': [2, 3],\n",
    "                'min_samples_leaf': [3, 4, 5],\n",
    "                'min_samples_split': [8, 10, 12],\n",
    "                'n_estimators': [100, 200, 300, 1000]\n",
    "            }\n",
    "            grid = GridSearchCV(estimator = RandomForestRegressor(), param_grid = param_grid, \n",
    "                                      cv = 3, n_jobs = -1, verbose = 2)\n",
    "        elif model == 'DecisionTree':\n",
    "            params = {\n",
    "                'max_depth': [2, 3, 5, 10, 20],\n",
    "                'min_samples_leaf': [5, 10, 20, 50, 100],\n",
    "                'criterion': [\"gini\", \"entropy\"]\n",
    "            }\n",
    "            grid = GridSearchCV(estimator=DecisionTreeClassifier(random_state=42), \n",
    "                                       param_grid=params, \n",
    "                                       cv=10, n_jobs=-1, verbose=1, scoring = \"accuracy\")\n",
    "        elif model == 'NearestNeighbour':\n",
    "            k_range = list(range(1, 31))\n",
    "            param_grid = dict(n_neighbors=k_range)\n",
    "\n",
    "            grid = GridSearchCV(KNeighborsClassifier(), param_grid, \n",
    "                                cv=10, scoring='accuracy', return_train_score=False,verbose=1)\n",
    "        elif model == 'NaiveBayes':\n",
    "            grid = MultinomialNB();\n",
    "        else:\n",
    "            grid = 0\n",
    "        return grid\n",
    "            \n",
    "        \n",
    " \n",
    "    def fit(self, x_train, y_train, algorithm):\n",
    "        model = algorithm.fit(x_train, y_train)\n",
    "        return model\n",
    "    \n",
    "    def predict(self, model, x_test):\n",
    "        result = np.round(model.predict(x_test))\n",
    "        return result\n",
    "    \n",
    "    def modelMetrics(self,model, X_test, y_test, y_test_pred):\n",
    "        print('Train MAE : ',metrics.mean_absolute_error(y_test,y_test_pred))\n",
    "        print('Train RMSE',np.sqrt(metrics.mean_squared_error(y_test,y_test_pred)))\n",
    "        print('R- Squared = ',metrics.r2_score (y_test, y_test_pred))\n",
    "        print(\"The MAE of the Model is:\", metrics.mean_absolute_error(y_test, y_test_pred))\n",
    "        print(\"Accuracy: \", metrics.accuracy_score(y_test, y_test_pred))\n",
    "        print ('Test confusion matrix \\n', metrics.confusion_matrix (y_test, y_test_pred))\n",
    "        print ('Classification report : \\n',metrics.classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "90bb26cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
      "0       GP   F   18       U     GT3       A     4     4   at_home   teacher   \n",
      "1       GP   F   17       U     GT3       T     1     1   at_home     other   \n",
      "2       GP   F   15       U     LE3       T     1     1   at_home     other   \n",
      "3       GP   F   15       U     GT3       T     4     2    health  services   \n",
      "4       GP   F   16       U     GT3       T     3     3     other     other   \n",
      "..     ...  ..  ...     ...     ...     ...   ...   ...       ...       ...   \n",
      "390     MS   M   20       U     LE3       A     2     2  services  services   \n",
      "391     MS   M   17       U     LE3       T     3     1  services  services   \n",
      "392     MS   M   21       R     GT3       T     1     1     other     other   \n",
      "393     MS   M   18       R     LE3       T     3     2  services     other   \n",
      "394     MS   M   19       U     LE3       T     1     1     other   at_home   \n",
      "\n",
      "     ... famrel freetime  goout  Dalc  Walc health absences    G1  G2    G3  \n",
      "0    ...      4        3    4.0     1     1      3        6   5.0   6   6.0  \n",
      "1    ...      5        3    3.0     1     1      3        4   5.0   5   6.0  \n",
      "2    ...      4        3    2.0     2     3      3       10   7.0   8  10.0  \n",
      "3    ...      3        2    2.0     1     1      5        2  15.0  14  15.0  \n",
      "4    ...      4        3    2.0     1     2      5        4   6.0  10  10.0  \n",
      "..   ...    ...      ...    ...   ...   ...    ...      ...   ...  ..   ...  \n",
      "390  ...      5        5    4.0     4     5      4       11   9.0   9   9.0  \n",
      "391  ...      2        4    5.0     3     4      2        3  14.0  16  16.0  \n",
      "392  ...      5        5    3.0     3     3      3        3  10.0   8   7.0  \n",
      "393  ...      4        4    1.0     3     4      5        0  11.0  12  10.0  \n",
      "394  ...      3        2    3.0     3     3      5        5   8.0   9   9.0  \n",
      "\n",
      "[395 rows x 33 columns]\n",
      "Number of Rows: 395\n",
      "Number of Columns: 33\n",
      "The dataset has 395 rows and 33 columns and has some missing values.\n",
      "Number of Rows: 649\n",
      "Number of Columns: 33\n",
      "The dataset has 649 rows and 33 columns and has some missing values.\n",
      "-The column 'Mjob', has'1' missing values.\n",
      "\n",
      "-The column 'guardian', has'1' missing values.\n",
      "\n",
      "-The column 'paid', has'1' missing values.\n",
      "\n",
      "-The column 'goout', has'1' missing values.\n",
      "\n",
      "-The column 'G1', has'1' missing values.\n",
      "\n",
      "-The column 'G3', has'1' missing values.\n",
      "\n",
      "-The column 'address', has'1' missing values.\n",
      "\n",
      "school        object\n",
      "sex           object\n",
      "age            int64\n",
      "address       object\n",
      "famsize       object\n",
      "Pstatus       object\n",
      "Medu           int64\n",
      "Fedu           int64\n",
      "Mjob          object\n",
      "Fjob          object\n",
      "reason        object\n",
      "guardian      object\n",
      "traveltime     int64\n",
      "studytime      int64\n",
      "failures       int64\n",
      "schoolsup     object\n",
      "famsup        object\n",
      "paid          object\n",
      "activities    object\n",
      "nursery       object\n",
      "higher        object\n",
      "internet      object\n",
      "romantic      object\n",
      "famrel         int64\n",
      "freetime       int64\n",
      "goout          int64\n",
      "Dalc           int64\n",
      "Walc           int64\n",
      "health         int64\n",
      "absences       int64\n",
      "G1             int64\n",
      "G2             int64\n",
      "G3             int64\n",
      "dtype: object\n",
      "school        object\n",
      "sex           object\n",
      "age            int64\n",
      "address       object\n",
      "famsize       object\n",
      "Pstatus       object\n",
      "Medu           int64\n",
      "Fedu           int64\n",
      "Mjob          object\n",
      "Fjob          object\n",
      "reason        object\n",
      "guardian      object\n",
      "traveltime     int64\n",
      "studytime      int64\n",
      "failures       int64\n",
      "schoolsup     object\n",
      "famsup        object\n",
      "paid          object\n",
      "activities    object\n",
      "nursery       object\n",
      "higher        object\n",
      "internet      object\n",
      "romantic      object\n",
      "famrel         int64\n",
      "freetime       int64\n",
      "goout          int64\n",
      "Dalc           int64\n",
      "Walc           int64\n",
      "health         int64\n",
      "absences       int64\n",
      "G1             int64\n",
      "G2             int64\n",
      "G3             int64\n",
      "dtype: object\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    path1 = 'Datasets\\student-mat.csv'\n",
    "    path2 = 'Datasets\\student-por.csv'\n",
    "    model_instance = DataPreparation(outcome = 'yes', features=None, categorical_features=None, one_hot_encoder=None)\n",
    "    data_math = model_instance.getData(path1, separator = ';')\n",
    "    print(data_math)\n",
    "    data_por = model_instance.getData(path2, separator = ';')\n",
    "    data_info_mat = model_instance.getDataInfo(data_math) \n",
    "    data_info_por = model_instance.getDataInfo(data_por)\n",
    "    data_math = model_instance.checkAndFillMissingValuesMode(data_math)\n",
    "    data_por = model_instance.checkAndFillMissingValuesMode(data_por)\n",
    "    features_types_mat = model_instance.getFeaturesTypes(data_math)\n",
    "    data_math = model_instance.changeFeatureType(data_math, 'float64', 'int64')\n",
    "    dat_por = model_instance.changeFeatureType(data_por, 'float64', 'int64')\n",
    "    \n",
    "    data_math = model_instance.replaceValues(['G1','G2','G3'], data_math, tipo = 'FiveLevels')\n",
    "    data_por = model_instance.replaceValues(['G1','G2','G3'], dat_por, tipo = 'FiveLevels')\n",
    "    \n",
    "    data_math, one_hot_math = model_instance.oneHotEncoding(data_math)\n",
    "    #independent_variables_math = model_instance.Vif(data_math,'G3')\n",
    "    data_math = model_instance.normalizeData(data_math,'G3')\n",
    "    X_train_math, X_test_math, y_train_math, y_test_math = model_instance.splitData(data_math, \n",
    "                                                                     data_math.columns[data_math.columns != 'G3'],\n",
    "                                                                     #independent_variables_math, \n",
    "                                                                     size_test = 0.3)\n",
    "    \n",
    "    data_por, one_hot_por = model_instance.oneHotEncoding(data_por)\n",
    "    #independent_variables_por = model_instance.Vif(data_por,'G3')\n",
    "    data_por = model_instance.normalizeData(data_por,'G3')\n",
    "    X_train_por, X_test_por, y_train_por, y_test_por = model_instance.splitData(data_por, \n",
    "                                                                     data_por.columns[data_por.columns != 'G3'], \n",
    "                                                                     #independent_variables_por,           \n",
    "                                                                     size_test = 0.3)\n",
    "    \n",
    "    print(X_train_por.columns != 'G3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b77760e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "30d62a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O algoritmo escolhido foi LogisticRegression\n",
      "Train MAE :  0.40336134453781514\n",
      "Train RMSE 0.7100716024967263\n",
      "R- Squared =  0.7340187751452839\n",
      "The MAE of the Model is: 0.40336134453781514\n",
      "Accuracy:  0.6218487394957983\n",
      "Test confusion matrix \n",
      " [[10  2  0  0  0]\n",
      " [10  5  7  0  0]\n",
      " [ 0  1  6  8  0]\n",
      " [ 0  0  5 17  8]\n",
      " [ 1  0  0  3 36]]\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.83      0.61        12\n",
      "           2       0.62      0.23      0.33        22\n",
      "           3       0.33      0.40      0.36        15\n",
      "           4       0.61      0.57      0.59        30\n",
      "           5       0.82      0.90      0.86        40\n",
      "\n",
      "    accuracy                           0.62       119\n",
      "   macro avg       0.57      0.59      0.55       119\n",
      "weighted avg       0.63      0.62      0.60       119\n",
      "\n",
      "O algoritmo escolhido foi DecisionTree\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "Train MAE :  0.19327731092436976\n",
      "Train RMSE 0.4936572484949417\n",
      "R- Squared =  0.8714424079868872\n",
      "The MAE of the Model is: 0.19327731092436976\n",
      "Accuracy:  0.8235294117647058\n",
      "Test confusion matrix \n",
      " [[11  1  0  0  0]\n",
      " [ 0 18  4  0  0]\n",
      " [ 0  0 13  2  0]\n",
      " [ 0  0  4 18  8]\n",
      " [ 0  1  0  1 38]]\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.92      0.96        12\n",
      "           2       0.90      0.82      0.86        22\n",
      "           3       0.62      0.87      0.72        15\n",
      "           4       0.86      0.60      0.71        30\n",
      "           5       0.83      0.95      0.88        40\n",
      "\n",
      "    accuracy                           0.82       119\n",
      "   macro avg       0.84      0.83      0.83       119\n",
      "weighted avg       0.84      0.82      0.82       119\n",
      "\n",
      "O algoritmo escolhido foi Svm\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.339 total time=   0.0s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.339 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.339 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.339 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.339 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.339 total time=   0.0s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.589 total time=   0.0s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.600 total time=   0.0s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.564 total time=   0.0s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.527 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.589 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.727 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.636 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.473 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.357 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.339 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.339 total time=   0.0s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.518 total time=   0.0s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.709 total time=   0.0s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.564 total time=   0.0s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.545 total time=   0.0s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.545 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.625 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.655 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.655 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.607 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.782 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.727 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.655 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.357 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.339 total time=   0.0s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.518 total time=   0.0s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.709 total time=   0.0s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.564 total time=   0.0s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.545 total time=   0.0s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.545 total time=   0.0s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.589 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.636 total time=   0.0s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.564 total time=   0.0s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.636 total time=   0.0s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.589 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.636 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.655 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.709 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.691 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.607 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.764 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.727 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.709 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.636 total time=   0.0s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.339 total time=   0.0s\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.327 total time=   0.0s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.518 total time=   0.0s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.709 total time=   0.0s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.564 total time=   0.0s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.545 total time=   0.0s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.545 total time=   0.0s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.589 total time=   0.0s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.618 total time=   0.0s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.564 total time=   0.0s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.636 total time=   0.0s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.518 total time=   0.0s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.600 total time=   0.0s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.618 total time=   0.0s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.636 total time=   0.0s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.545 total time=   0.0s\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.589 total time=   0.0s\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.691 total time=   0.0s\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "Train MAE :  0.29411764705882354\n",
      "Train RMSE 0.6284568268332179\n",
      "R- Squared =  0.7916480405304724\n",
      "The MAE of the Model is: 0.29411764705882354\n",
      "Accuracy:  0.7310924369747899\n",
      "Test confusion matrix \n",
      " [[11  1  0  0  0]\n",
      " [ 6 10  6  0  0]\n",
      " [ 0  0  9  6  0]\n",
      " [ 0  0  4 19  7]\n",
      " [ 1  0  0  1 38]]\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.92      0.73        12\n",
      "           2       0.91      0.45      0.61        22\n",
      "           3       0.47      0.60      0.53        15\n",
      "           4       0.73      0.63      0.68        30\n",
      "           5       0.84      0.95      0.89        40\n",
      "\n",
      "    accuracy                           0.73       119\n",
      "   macro avg       0.71      0.71      0.69       119\n",
      "weighted avg       0.76      0.73      0.72       119\n",
      "\n",
      "O algoritmo escolhido foi RandomForest\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "Train MAE :  0.7058823529411765\n",
      "Train RMSE 0.9348527048856053\n",
      "R- Squared =  0.5389658769184922\n",
      "The MAE of the Model is: 0.7058823529411765\n",
      "Accuracy:  0.3697478991596639\n",
      "Test confusion matrix \n",
      " [[ 0  5  7  0  0]\n",
      " [ 0  5 17  0  0]\n",
      " [ 0  0  9  6  0]\n",
      " [ 0  0  2 28  0]\n",
      " [ 0  1  0 37  2]]\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        12\n",
      "           2       0.45      0.23      0.30        22\n",
      "           3       0.26      0.60      0.36        15\n",
      "           4       0.39      0.93      0.55        30\n",
      "           5       1.00      0.05      0.10        40\n",
      "\n",
      "    accuracy                           0.37       119\n",
      "   macro avg       0.42      0.36      0.26       119\n",
      "weighted avg       0.55      0.37      0.27       119\n",
      "\n",
      "O algoritmo escolhido foi NearestNeighbour\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Train MAE :  0.3949579831932773\n",
      "Train RMSE 0.6798418006783489\n",
      "R- Squared =  0.7561838772165103\n",
      "The MAE of the Model is: 0.3949579831932773\n",
      "Accuracy:  0.6302521008403361\n",
      "Test confusion matrix \n",
      " [[ 7  5  0  0  0]\n",
      " [ 4 11  6  1  0]\n",
      " [ 0  1  5  9  0]\n",
      " [ 0  0  3 18  9]\n",
      " [ 0  1  0  5 34]]\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.58      0.61        12\n",
      "           2       0.61      0.50      0.55        22\n",
      "           3       0.36      0.33      0.34        15\n",
      "           4       0.55      0.60      0.57        30\n",
      "           5       0.79      0.85      0.82        40\n",
      "\n",
      "    accuracy                           0.63       119\n",
      "   macro avg       0.59      0.57      0.58       119\n",
      "weighted avg       0.63      0.63      0.63       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    model_ml_math = SupervisedMlModels(x_train=None, x_test=None, y_train=None, y_test = None)\n",
    "    algorithms_math = ['LogisticRegression','DecisionTree','Svm','RandomForest','NearestNeighbour']\n",
    "    for algorithm in algorithms_math:\n",
    "        model_math = model_ml_math.hyperparameterTuning(algorithm)\n",
    "        if model_math != 0:\n",
    "            print('O algoritmo escolhido foi',algorithm)\n",
    "            model_ml_math.fit(X_train_math, y_train_math, model_math)\n",
    "            y_test_pred_math = model_ml_math.predict(model_math,X_test_math)\n",
    "            model_ml_math.modelMetrics(model_math,X_test_math,y_test_math, y_test_pred_math)\n",
    "            pickle.dump(model_math,open(\"Models/Maths/FiveLevels/\"+algorithm+'.pkl','wb'))\n",
    "        else:\n",
    "            print(\"O seguinte modelo n√£o existe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cbae934b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O algoritmo escolhido foi LogisticRegression\n",
      "Train MAE :  0.35384615384615387\n",
      "Train RMSE 0.6283882516977819\n",
      "R- Squared =  0.7337293846426671\n",
      "The MAE of the Model is: 0.35384615384615387\n",
      "Accuracy:  0.6615384615384615\n",
      "Test confusion matrix \n",
      " [[13  5  1  1  0]\n",
      " [10 19  7  0  0]\n",
      " [ 0 10 27  6  0]\n",
      " [ 0  0  7 48 11]\n",
      " [ 0  0  0  8 22]]\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.65      0.60        20\n",
      "           2       0.56      0.53      0.54        36\n",
      "           3       0.64      0.63      0.64        43\n",
      "           4       0.76      0.73      0.74        66\n",
      "           5       0.67      0.73      0.70        30\n",
      "\n",
      "    accuracy                           0.66       195\n",
      "   macro avg       0.64      0.65      0.65       195\n",
      "weighted avg       0.66      0.66      0.66       195\n",
      "\n",
      "O algoritmo escolhido foi DecisionTree\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "Train MAE :  0.28205128205128205\n",
      "Train RMSE 0.5593035962878415\n",
      "R- Squared =  0.789058343677957\n",
      "The MAE of the Model is: 0.28205128205128205\n",
      "Accuracy:  0.7282051282051282\n",
      "Test confusion matrix \n",
      " [[18  1  0  1  0]\n",
      " [13 12 11  0  0]\n",
      " [ 0  3 32  8  0]\n",
      " [ 0  0  0 56 10]\n",
      " [ 0  0  0  6 24]]\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.90      0.71        20\n",
      "           2       0.75      0.33      0.46        36\n",
      "           3       0.74      0.74      0.74        43\n",
      "           4       0.79      0.85      0.82        66\n",
      "           5       0.71      0.80      0.75        30\n",
      "\n",
      "    accuracy                           0.73       195\n",
      "   macro avg       0.71      0.73      0.70       195\n",
      "weighted avg       0.74      0.73      0.71       195\n",
      "\n",
      "O algoritmo escolhido foi Svm\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.549 total time=   0.0s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.670 total time=   0.0s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.615 total time=   0.0s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.582 total time=   0.0s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.556 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.560 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.725 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.637 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.615 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.544 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.330 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.319 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.363 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.356 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.308 total time=   0.0s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.311 total time=   0.0s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.560 total time=   0.0s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.692 total time=   0.0s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.659 total time=   0.0s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.615 total time=   0.0s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.670 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.725 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.725 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.648 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.604 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.725 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.659 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.615 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.556 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.341 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.341 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.363 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.378 total time=   0.0s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.308 total time=   0.0s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.311 total time=   0.0s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.560 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.692 total time=   0.0s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.659 total time=   0.0s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.615 total time=   0.0s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.615 total time=   0.0s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.681 total time=   0.0s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.648 total time=   0.0s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.692 total time=   0.0s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.736 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.725 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.725 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.615 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.689 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.604 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.725 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.659 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.626 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.556 total time=   0.0s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.297 total time=   0.0s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.308 total time=   0.0s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.311 total time=   0.0s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.560 total time=   0.0s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.692 total time=   0.0s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.659 total time=   0.0s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.615 total time=   0.0s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.615 total time=   0.0s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.681 total time=   0.0s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.648 total time=   0.0s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.703 total time=   0.0s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.637 total time=   0.0s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.681 total time=   0.0s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.615 total time=   0.0s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.681 total time=   0.0s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.589 total time=   0.0s\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.725 total time=   0.0s\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.725 total time=   0.0s\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.593 total time=   0.0s\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.700 total time=   0.0s\n",
      "Train MAE :  0.28205128205128205\n",
      "Train RMSE 0.5593035962878415\n",
      "R- Squared =  0.789058343677957\n",
      "The MAE of the Model is: 0.28205128205128205\n",
      "Accuracy:  0.7282051282051282\n",
      "Test confusion matrix \n",
      " [[13  6  0  1  0]\n",
      " [ 6 19 11  0  0]\n",
      " [ 0  2 33  8  0]\n",
      " [ 0  0  1 56  9]\n",
      " [ 0  0  0  9 21]]\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.65      0.67        20\n",
      "           2       0.70      0.53      0.60        36\n",
      "           3       0.73      0.77      0.75        43\n",
      "           4       0.76      0.85      0.80        66\n",
      "           5       0.70      0.70      0.70        30\n",
      "\n",
      "    accuracy                           0.73       195\n",
      "   macro avg       0.72      0.70      0.70       195\n",
      "weighted avg       0.73      0.73      0.72       195\n",
      "\n",
      "O algoritmo escolhido foi RandomForest\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "Train MAE :  0.48205128205128206\n",
      "Train RMSE 0.7302967433402214\n",
      "R- Squared =  0.6403617662706154\n",
      "The MAE of the Model is: 0.48205128205128206\n",
      "Accuracy:  0.5384615384615384\n",
      "Test confusion matrix \n",
      " [[ 0 18  1  1  0]\n",
      " [ 0 17 19  0  0]\n",
      " [ 0  2 37  4  0]\n",
      " [ 0  0 15 51  0]\n",
      " [ 0  0  1 29  0]]\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.46      0.47      0.47        36\n",
      "           3       0.51      0.86      0.64        43\n",
      "           4       0.60      0.77      0.68        66\n",
      "           5       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.54       195\n",
      "   macro avg       0.31      0.42      0.36       195\n",
      "weighted avg       0.40      0.54      0.46       195\n",
      "\n",
      "O algoritmo escolhido foi NearestNeighbour\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Train MAE :  0.4205128205128205\n",
      "Train RMSE 0.6868732574462859\n",
      "R- Squared =  0.6818584855470828\n",
      "The MAE of the Model is: 0.4205128205128205\n",
      "Accuracy:  0.6\n",
      "Test confusion matrix \n",
      " [[15  4  0  1  0]\n",
      " [ 7 16 11  2  0]\n",
      " [ 0  6 32  5  0]\n",
      " [ 0  0 14 48  4]\n",
      " [ 0  0  0 24  6]]\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.75      0.71        20\n",
      "           2       0.62      0.44      0.52        36\n",
      "           3       0.56      0.74      0.64        43\n",
      "           4       0.60      0.73      0.66        66\n",
      "           5       0.60      0.20      0.30        30\n",
      "\n",
      "    accuracy                           0.60       195\n",
      "   macro avg       0.61      0.57      0.57       195\n",
      "weighted avg       0.60      0.60      0.58       195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    model_ml_por = SupervisedMlModels(x_train=None, x_test=None, y_train=None, y_test = None)\n",
    "    algorithms_por = ['LogisticRegression','DecisionTree','Svm','RandomForest','NearestNeighbour']\n",
    "    for algorithm in algorithms_por:\n",
    "        model_por = model_ml_por.hyperparameterTuning(algorithm)\n",
    "        if model_por != 0:\n",
    "            print('O algoritmo escolhido foi',algorithm)\n",
    "            model_ml_por.fit(X_train_por, y_train_por, model_por)\n",
    "            y_test_pred_por = model_ml_por.predict(model_por,X_test_por)\n",
    "            model_ml_por.modelMetrics(model_por,X_test_por,y_test_por, y_test_pred_por)\n",
    "            pickle.dump(model_por,open(\"Models/Portuguese/FiveLevels/\"+algorithm+'.pkl','wb'))\n",
    "        else:\n",
    "            print(\"O seguinte modelo n√£o existe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471d6067",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_por)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c81d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_por.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492a9a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f911844e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53f9aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe7d2c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f528be2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
